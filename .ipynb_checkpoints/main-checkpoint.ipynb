{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a='1'\n",
    "a.split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main.py', '-n', '100']\n",
      "Namespace(niter=100)\n"
     ]
    }
   ],
   "source": [
    "# original code by github.com/devnag\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "    \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-n', '--niter', default=300, type=int)\n",
    "# parser.add_argument('-lr', default=0.2e-4, type=int)\n",
    "\n",
    "if os.sys.argv[0].find('ipykernel') >= 0:\n",
    "    prog_eg = 'main.py -n 100'\n",
    "    os.sys.argv = prog_eg.split(' ')\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "\n",
    "    #####################################################################\n",
    "    ## Parameters\n",
    "    #####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-1d41dd92dede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m## Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m#####################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0md_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distribution_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_stddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mgi_sampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_generator_input_sampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg_input_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg_output_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_mean' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#####################################################################\n",
    "## Data\n",
    "#####################################################################\n",
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "## Models\n",
    "#####################################################################\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.sigmoid(self.map2(x))\n",
    "        return self.map3(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.map1(x))\n",
    "        x = F.elu(self.map2(x))\n",
    "        return F.sigmoid(self.map3(x))\n",
    "\n",
    "\n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "\n",
    "def decorate_with_diffs(data, exponent):\n",
    "    mean = torch.mean(data.data, 1)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    return torch.cat([data, diffs], 1)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "## Initialization\n",
    "#####################################################################\n",
    "d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "gi_sampler = get_generator_input_sampler()\n",
    "G = Generator(input_size=g_input_size, hidden_size=g_hidden_size, output_size=g_output_size)\n",
    "D = Discriminator(input_size=d_input_func(d_input_size), hidden_size=d_hidden_size, output_size=d_output_size)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(D.parameters(), lr=args.lr, betas=optim_betas)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr=args.lr, betas=optim_betas)\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "## Optimize\n",
    "#####################################################################\n",
    "for epoch in range(args.niter):\n",
    "    for d_index in range(d_steps):\n",
    "        # train D on real+fake\n",
    "        D.zero_grad()\n",
    "\n",
    "        # train D on real\n",
    "        d_real_data = Variable(d_sampler(d_input_size))\n",
    "        d_real_decision = D(preprocess(d_real_data))\n",
    "        d_real_error = criterion(d_real_decision, Variable(torch.ones(1)))\n",
    "        d_real_error.backward()\n",
    "\n",
    "        # train D on fake\n",
    "        d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        d_fake_data = G(d_gen_input).detach()\n",
    "        d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "        d_fake_error = criterion(d_fake_decision, Variable(torch.zeros(1)))\n",
    "        d_fake_error.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "    for g_index in range(g_steps):\n",
    "        G.zero_grad()\n",
    "\n",
    "        gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "        g_fake_data = G(gen_input)\n",
    "        dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "        g_error = criterion(dg_fake_decision, Variable(torch.ones(1)))\n",
    "\n",
    "        g_error.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    if epoch % print_interval == 0:\n",
    "        print(\"%4d: D, %s/%s G: %s (Real: %s, Fake: %s) \" % (epoch,\n",
    "                                                            extract(d_real_error)[0],\n",
    "                                                            extract(d_fake_error)[0],\n",
    "                                                            extract(g_error)[0],\n",
    "                                                            stats(extract(d_real_data)),\n",
    "                                                            stats(extract(d_fake_data))\n",
    "                                                            )\n",
    "              )\n",
    "\n",
    "# check the results\n",
    "\n",
    "gen_input = Variable(gi_sampler(1000, g_input_size))\n",
    "g_fake_data = G(gen_input)\n",
    "g_numpy = g_fake_data.data.numpy()\n",
    "# plt.plot(g_fake_data.data.numpy())\n",
    "plt.hist(g_numpy)\n",
    "plt.show()\n",
    "\n",
    "#plt.plot([1,2,3])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
